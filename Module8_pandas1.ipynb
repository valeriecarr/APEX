{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Module8_pandas1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valeriecarr/APEX/blob/main/Module8_pandas1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnXOxVPEkZ5f"
      },
      "source": [
        "<img src='https://cdn.pixabay.com/photo/2019/09/08/19/54/panda-4461766_1280.jpg' width=700>  \n",
        "Photo by qgadrian production from Pixabay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svAPrOFekdFH"
      },
      "source": [
        "# APEX Faculty Training, Module 8: Pandas Part 1\n",
        "\n",
        "Created by Valerie Carr and Jaime Zuspann  \n",
        "Licensed under a Creative Commons license: CC BY-NC-SA  \n",
        "Last updated: Feb 18, 2022  \n",
        "\n",
        "**Learning outcomes**  \n",
        "1. Learn to read in spreadsheet data (\"dataframes\") in Python with the Pandas library.\n",
        "2.  Learn to manipulate the contents of a dataframe with Pandas methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI79e_J1lAAH"
      },
      "source": [
        "## 1. A couple notes before you start\n",
        "* This file is view only, meaning that you can't edit it.\n",
        "    * To create an editable copy, look towards the top of the notebook and click on `Copy to Drive`. This will cause a new tab to open with your own personal copy.\n",
        "    * If you want to refer back to your copy in the future, you can find it in Google Drive in a folder called `Colab Notebooks`.\n",
        "* To run a cell, use `shift` + `enter`.   \n",
        "* Keep the following Python style preferences in mind:\n",
        "    * Variable names should use `snake_case`\n",
        "    * Include spaces before and after operators, e.g., `x + 1`\n",
        "    * Don't put unnecessary spaces after a function name, before the parentheses\n",
        "        * Correct: `print(my_variable)`\n",
        "        * Incorrect: `print (my_variable)`\n",
        "    * Don't put unnecessary spaces at the beginning or end of parentheses\n",
        "        * Correct: `print(my_variable)`\n",
        "        * Incorrect: `print( my_variable )`\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKwAYq8KJjo7"
      },
      "source": [
        "## 2. What is (are?) Pandas?  \n",
        "Pandas is a Python library that provides tools for working with rows and columns of data. In other words, it's useful for working with  data in spreadsheet form. In Pandas, however, we use the term \"dataframe\" rather than spreadsheet.  \n",
        "\n",
        "Pandas is used to organize, clean, and view data, similar to what you might do in Excel or Sheets. This library is useful because it:\n",
        "* Can easily work with large data sets\n",
        "* Is much easier to write code that organizes and cleans your data than do these tedious tasks by hand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E48I6l-ervev"
      },
      "source": [
        "## 3. Pandas Dataframes\n",
        "Dataframes are Python data types, just as integers, floats, strings, and lists are. Dataframes have special properties and methods that can be applied to them. As you can see in the example below, a dataframe looks much like a spreadsheet.  \n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<th></th>\n",
        "<th>state</th>\n",
        "<th>totalPop</th>\n",
        "<th>hispPop</th>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>0</td>\n",
        "<td>Alabama</td>\n",
        "<td>4779736</td>\n",
        "<td>185602</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>1</td>\n",
        "<td>Alaska</td>\n",
        "<td>710231</td>\n",
        "<td>39249</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>2</td>\n",
        "<td>Arizona</td>\n",
        "<td>6392017</td>\n",
        "<td>1895149</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>3</td>\n",
        "<td>Arkansas</td>\n",
        "<td>2915918</td>\n",
        "<td>186050</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>4</td>\n",
        "<td>California</td>\n",
        "<td>37253956</td>\n",
        "<td>14013719</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "### 3a. Creating Dataframes  \n",
        "Typically, dataframes are created by reading in a file. The most common file type used with Pandas is a CSV file, e.g., `my_file.csv`. Files created in Excel and Sheets can be exported as CSV files, so if you have an existing dataset, you can save it as a CSV file and read it in with Pandas.  \n",
        "\n",
        "### 3b. Using Pandas  \n",
        "A Python library, such as Pandas, has to be imported before its functions can be used. It is best to include this import code at the top of a given notebook.\n",
        "\n",
        "To import Pandas, use the keyword `import` followed by the library name, `pandas`. It is also standard to use an abbreviation when importing libraries; for pandas, this abbreviation is `pd`. Putting this all together, we can import Pandas with the following line of code:\n",
        "\n",
        "`import pandas as pd`  \n",
        "\n",
        "<font color='red'>Exercise 1</font>  \n",
        "Copy and paste the code above into the cell below, making sure to run the cell. You won't see any output, but this step is necessary to use Pandas functions in subsequent exercises."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjOCmnIDfaw8"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0TsiC-If58b"
      },
      "source": [
        "## 4. Reading in Files\n",
        "How does one open a CSV file in Python? In Excel or Sheets, you would normally click the \"open\" icon and select the file of interest. The process is a bit different with Python, but generally involves the same steps: telling Python that you want to open (or \"read\") a file, and then specifying which file it is that you want to read.\n",
        "\n",
        "Pandas has a function `read_csv()` that reads in csv files and converts the content to a dataframe. The generic syntax looks like this:\n",
        "\n",
        "`my_df = pd.read_csv(filepath)`  \n",
        "\n",
        "Breaking down this syntax:\n",
        "* `my_df` is a generic variable name that represents the dataframe that you're creating. You can, of course, choose any variable name that you like.\n",
        "* `pd` is the abbreviation for Pandas; essentially, we're saying, \"I want to use a function within the Pandas library\"\n",
        "* `read_csv()` is the specific function within Pandas that we'll use to read in the CSV file and create the dataframe\n",
        "* Finally, `filepath` is the location and name of the CSV file in question\n",
        "\n",
        "For the purposes of this tutorial, we'll be using a CSV file stored on GitHub, which can be accessed via a URL. Below, you'll see that we created the variable `filepath` and assigned it a string with the desired URL.\n",
        "\n",
        "In a future module, we'll teach you how to create your own GitHub account where you can add data files, and we'll also teach you a couple alternate approaches that utilize Google Drive.\n",
        "\n",
        "<font color='red'>Exercise 2</font>  \n",
        "One line 1 below, we've defined the filepath for you. Insert a new line in the cell, and use the code provided above to create a dataframe named `my_df` that uses this filepath. Be sure to run the cell when you're done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGuiFay7gr4a"
      },
      "source": [
        "filepath = \"https://raw.githubusercontent.com/valeriecarr/engr120/main/S21/state_pop.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06jff3d4eil-"
      },
      "source": [
        "## 5. Viewing Dataframes  \n",
        "### 5a. `head()` and `tail()`\n",
        "Now that we've created the dataframe, let's check to make sure it looks as we expect it to â€“ data arranged in rows and columns. Pandas has a helpful method `head()` that displays the header (i.e., column names) and first few rows of a dataframe. The syntax for using this method is as follows:\n",
        "\n",
        "`my_df.head()`  \n",
        "\n",
        "<font color='red'>Exercise 3</font>  \n",
        "Copy and paste the code from above into the cell below, and run the cell. You should now see the first few rows of the dataframe you created in Exercise 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcDZjBqmrvew"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufJDn2jFrve4"
      },
      "source": [
        "By default, the `head()` method displays the first 5 rows of data. Providing a number in the parentheses will instead show a specific number of entries. For instance: `my_df.head(6)` would display 6 rows, rather than the default of 5 rows.  \n",
        "\n",
        "Similarly, you can use `tail()` to display the last few rows of a dataframe. The default for this method is also 5 with the option to specify a different number as desired. The syntax for this method is:\n",
        "\n",
        "`my_df.tail()`\n",
        "\n",
        "<font color='red'>Exercise 4</font>  \n",
        "In the cell below, display the first 7 rows of `my_df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYBeCEQrrve4"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>Exercise 5</font>  \n",
        "Next, display the last 3 rows of the dataframe."
      ],
      "metadata": {
        "id": "CTaFKpnBEbtW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W0sOXPUREsds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you would like to see the *entire* dataframe, you can simply type its name, in this case, `my_df`. This works fine for small dataframes like the one we're using in this tutorial, but it's typically not helpful to spit out a huge dataframe in your notebook. So, you may not use this command very often!"
      ],
      "metadata": {
        "id": "8YOOPnIXeVcI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RMD1SS8lEn5"
      },
      "source": [
        "### 5b. Single Column  \n",
        "You can display a single column of a dataframe by using either the Attribute approach or the Label approach.\n",
        "\n",
        "The syntax for the **Attribute approach** is as follows, with `col_name` being a generic stand-in for the column in which you're interested:\n",
        "\n",
        "`my_df.col_name`   \n",
        "\n",
        "The syntax for the **Label approach** is as follows. Importantly, note that when using this approach, you must put the column name in quotes:\n",
        "\n",
        "`my_df['col_name']`  \n",
        "\n",
        "<font color='red'>Exercise 6</font>  \n",
        "Run the cell below to see the column `totalPop` displayed using the **Attribute** approach."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_df.totalPop"
      ],
      "metadata": {
        "id": "sPxylw5DgnMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>Exercise 7</font>  \n",
        "Now try displaying the column hispPop in the cell below using the **Label** approach. Refer to the syntax just above!"
      ],
      "metadata": {
        "id": "DDvOcT9wg60p"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pm0ENFyjhLPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Subsetting Dataframes\n",
        "Subsetting a dataframe allows you to view just a portion (a subset) of the dataframe. The section above shows a few ways to do this, but they're relatively limited. The methods covered in this section let you take complete control over which entries to display.\n",
        "\n",
        "Generally speaking, dataframes are organized as follows:  \n",
        "* Each column is a variable (e.g., `totalPop`, `hispPop`)\n",
        "* Each row is an observation (e.g., data for a particular state)\n",
        "\n",
        "We can subset a dataframe according to variables (columns) or observations (rows).\n",
        "\n",
        "### 6a. Subsetting Observations\n",
        "Subsetting observations is accomplished using Boolean expressions to select portions of the dataframe that meet some criteria.  \n",
        "\n",
        "Say, for example, that we want to view data from all states with a total population greater than 15 million. We could accomplish this using the line of code below:  \n",
        "\n",
        "`my_df[my_df.totalPop > 15000000]`  \n",
        "\n",
        "Breaking down the syntax:\n",
        "* First, we need to specify which dataframe to subset (`my_df`)\n",
        "* Next, we use square brackets with a Boolean expression inside to indicate *how* we want to subset the dataframe in question\n",
        "* In our case, we're specifying that we want to look in the `totalPop` column for values greater than 15 million\n",
        "* The output of this code will be observations (rows) meeting our criteria  \n",
        "\n",
        "<font color='red'>Exercise 8</font>  \n",
        "Run the cell below to see this subsetting method in action."
      ],
      "metadata": {
        "id": "DccpWhOgPwd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_df[my_df.totalPop > 15000000]"
      ],
      "metadata": {
        "id": "pW4rm5omfi2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the same general syntax to find observations that meet any criteria we're interested in. You essentially just need to choose three things (in addition, of course, to indicating which dataframe is relevant):  \n",
        "\n",
        "* The column you're interested in\n",
        "* A Boolean operator (such as <, <=, >, >=, ==, !=)\n",
        "* A value (a string or number)  \n",
        "\n",
        "All together, the general syntax looks like this:  \n",
        ">`df_name[df_name.col_name == value]`  \n",
        "\n",
        "where `==` can be replaced with any comparison operator.  \n",
        "\n",
        "<font color='red'>Exercise 9</font>  \n",
        "Subset `my_df` to show data for only `'California'`. Hint: you'll need to think about which column contains the state names, and how to check whether any state names in that column are equivalent to 'California'."
      ],
      "metadata": {
        "id": "EvCC2nrchLbj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zh5mtKGMjx7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>Exercise 10</font>  \n",
        "Now display only the data for states with a Hispanic population less than or equal to 20 thousand. Again, think about which column to specify."
      ],
      "metadata": {
        "id": "rWOWCcGnjyee"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M0SPMC8lkCdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6b. Multiple Criteria\n",
        "We can also combine Boolean expressions to make more complex criteria:\n",
        "* Data that meet criteria 1 *and* 2\n",
        "* Data that meet criteria 1 *or* 2  \n",
        "\n",
        "The syntax here is different than what you've previously learned about combining Boolean expressions, which was to simply use the words `and` and `or`.\n",
        "\n",
        "In Pandas, we instead use symbols:\n",
        "* The `&` symbol represents `and`\n",
        "* The `|` symbol (\"pipe\") represents `or`\n",
        "\n",
        "See below for pseudocode examples of each:\n",
        "\n",
        "And: `my_df[(criteria1) & (criteria2)]`  \n",
        "Or: `my_df[(criteria1) | (criteria2)]`\n",
        "\n",
        "Note: It is important to put parentheses around each criteria, i.e., each set of Boolean expressions. The precedence of the `&` and `|` operators is greater than that of the comparison operators, so the parentheses help to force Pandas to attend to each Boolean expression first.\n",
        "\n",
        "<font color='red'>Exercise 11</font>  \n",
        "Run the cell below to see the subset of states with a total population over 7 million and a Hispanic population over 1 million."
      ],
      "metadata": {
        "id": "V5N4Vs7kkHam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_df[(my_df.totalPop > 7000000) & (my_df.hispPop > 1000000)]"
      ],
      "metadata": {
        "id": "DkN3gUFTmopA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>Exercise 12</font>  \n",
        "Now write your own code to display the states that have a total population less than 800 thousand **or** a Hispanic population greater than 5 million."
      ],
      "metadata": {
        "id": "Xx__BicqnzIm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lROK3CsqnAHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6c. Combining Math and Boolean Expressions\n",
        "With Pandas, it's very easy to perform mathematical operations on columns. We can add, subtract, multiply, and divide values from different columns. Then, we can compare the resulting value to some criteria with a Boolean expression.  \n",
        "\n",
        "For example, which states have a greater than 30% Hispanic population? First, we need to divide `hispPop` by `totalPop` and then assess which values are greater than 0.3. We can do all this with a single command!  \n",
        "\n",
        "<font color='red'>Exercise 13</font>  \n",
        "Below is the line of code that answers the question. Run the cell to see the output."
      ],
      "metadata": {
        "id": "86hD-cuyoayE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_df[(my_df.hispPop / my_df.totalPop) > 0.3]"
      ],
      "metadata": {
        "id": "lfrpqdoNpqi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>Exercise 14</font>  \n",
        "Now display the states that have a population greater than 5 million, of which less than 10% is Hispanic."
      ],
      "metadata": {
        "id": "_hk-B_skrGrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_df[(my_df.totalPop > 5000000) & ((my_df.hispPop / my_df.totalPop) < 0.05)]"
      ],
      "metadata": {
        "id": "8fdAwncOrVR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>Exercise 15</font>  \n",
        "Now that you know how to create complex criteria, try out one of your own below! Feel free to choose whatever sounds interesting."
      ],
      "metadata": {
        "id": "gtj7Mp5ltPiI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ohvDlwGHtQTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All done!\n",
        "Congrats on finishing the Pandas module! In the next module, we'll dive deeper into working with dataframes using the Pandas library."
      ],
      "metadata": {
        "id": "vYqInSA0L4Ph"
      }
    }
  ]
}